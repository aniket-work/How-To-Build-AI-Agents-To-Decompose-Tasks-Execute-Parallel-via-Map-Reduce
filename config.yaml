model_settings:
  name: "llama-3.2-1b-preview"
  temperature: 0.7
  max_tokens: 1024